---
title: "[Kubernetes] 쿠버네티스 서비스"
categories:
    - study
tags:
    - kubernetes
    - k8s

toc: true
toc_sticky: true
toc_label: Table of contents

last_modified_at: 2021-10-26
---


## 3.3 쿠버네티스 연결을 담당하는 서비스
- 쿠버네티스에서는 외부에서 쿠버네티스 클러스터에 접속하는 방법을 `서비스`라고 한다.

### 3.3.1 가장 간단하게 연결하는 노드포트
- `노드포트` 서비스를 이용하여 외부에서 쿠버네티스 클러스터의 내부에 쉽게 접근할 수 있다.

#### 노드포트 서비스로 외부에서 접속하기
- 아래 명령어로 노드포트 서비스를 생성 할수 었다.
  ```sh
  kebuctl create -f nodeport.yaml
  ```  
  nodeport.yaml
  ```yaml
  apiVersion: v1
  kind: Service
  metadata:
    name: np-svc
  spec:
    selector:
      app: np-pods
    ports:
      - name: http
        protocol: TCP
        port: 80
        targetPort: 80
        nodePort: 30000
    type: NodePort
  ```

- `kubectl get services`를 실행해 노드포트 서비스로 생성한 np-svc 서비스 확인
  ```sh
  kubectl get services
  ```

- 워커 노드 IP 확인
  ```sh
  kubectl get nodes -o wide
  ```

- 웹 브라우저에서 확인 된 워커 노드 IP 접속
  ```
  http://192.168.1.101:30000
  ```

#### 부하 분산 테스트하기


#### expose로 노드포트 서비스 생성하기
- 노드포트 서비스는 오브젝트 스펙 파일로만 생성하는것 뿐만 아니라 expose 명령어로도 생성할 수 있다.
- 디플로이먼트를 np-pods로 지정, 서비스의 이름은 np-svc-v2, 타입은 NodePort로 지정, 마지막으로 서비스가 파드로 보내줄 연결 포트를 80번으로 지정
  ```sh
  kubectl expose deployment np-pods --type=NodePort --name=np-svc-v2 --port=80
  ```
- 서비스 확인
  ```sh
  kubectl get services
  ```

### 3.3.2 사용 목적별로 연결하는 인그레스
- `인그레스`는 고유한 주소를 제공해 사용 목적에 따라 다른 응답을 제공하도록 하고, 트래픽에 대한 L4/L7 로드밸런서와 보안 인증서를 처리하는 기능을 제공한다.
- `인그레스`를 사용하기 위해서는 인그레스 컨트롤러가 필요하다.
- `인그레스`를 위한 설정 파일 예시
  
  ingress-config.yaml

  ```yaml
  apiVersion: networking.k8s.io/v1beta1
  kind: Ingress
  metadata:
    name: ingress-nginx # 이름을 통해서 통신할 ingress 컨트롤러를 확인
    annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
  spec:
    rules: # 규칙을 지정
    - http:
        paths: 
        - path: #기본 경로 규칙
          backend: # 연결되는 서비스와 포트
            serviceName: hname-svc-default
            servicePort: 80
        - path: /ip
          backend:
            serviceName: ip-svc
            servicePort: 80
        - path: /your-directory
          backend:
            serviceName: your-svc
            servicePort: 80
  ```
- `kubectl get ingress -o yaml` 명령어를 통해 인그레스 내용이 확실하게 적용됬는지 확인 가능.
- 포트 포워딩 기능 예시
  
  ingress.yaml

  ```yaml
  apiVersion: v1
  kind: Service
  metadata:
    name: nginx-ingress-controller
    namespace: ingress-nginx
  spec:
    ports:
    - name: http
      protocol: TCP
      port: 80
      targetPort: 80
      nodePort: 30100
    - name: https
      protocol: TCP
      port: 443
      targetPort: 443
      nodePort: 30101
    selector:
      app.kubernetes.io/name: ingress-nginx
    type: NodePort
  ```

### 3.3.3 클라우드에서 쉽게 구성 가능한 로드밸런서
- 쿠버네티스에서는 `로드밸런서`라는 서비스 타입을 제공해 파드를 외부에 노출하고 부하를 분산 한다.
- 클라우드에서 제공하는 쿠버네티스를 사용하고 있다면 다음과 같은 선언으로 사용할 수 있다.
  ```sh
  kubectl expose deployment ex-lb --type=LoadBalancer --name=ex-svc
  ```

### 3.3.4 온프레미스에서 로드밸런서를 제공하는 MetalLB
- `MetalLB`는 베어메탈(운영체제가 설지되지 않은 하드웨어)로 구성된 쿠버네티스에서도 로드밸런서를 사용할 수 있게 고안된 프로젝트이다.
- `MetalLB`는 기존의 L2 네트워크와 L3 네트워크로 로드밸런서를 구현한다.
- `MetalLB` 컨트롤러는 작동 방식을 정의하고, EXTERNAL-IP를 부여해 관리 한다.
- `MetalLB`는 ConfigMap 오브젝트를 사용하는데, 설정 예시는 다음과 같다.
  
  metallb-l2config.yaml
  
  ```yaml
  apiVersion: v1
  kind: ConfigMap
  metadata:
    namespace: metallb-system
    name: config
  data:
    config: |
      address-pools:
      - name: nginx-ip-range
        protocol: layer2
        addresses:
        - 192.168.1.11-192.168.1.13
  ```
- configMap 생성여부 및 적용이 잘 됬는지는 아래 명령어로 확인 가능.
  ```sh
  kubectl get configmap -n metallb-system # 생성 확인
  kubectl get configmap -n metallb-system -o yaml # 적용 확인
  kubectl expose deployment lb-hname-pods --type=LoadBalancer --name=lb-hname-svc --port=80 # 각 디플로이먼트를 로드밸런서 서비스로 노출
  ```

### 3.3.5 부하에 따라 자동으로 파드 수를 조절하는 HPA
- 부하량에 따라 디플로이먼트의 파드 수를 유동적으로 관리하는 기능을 `HPA`라고 한다.
- 부하량 확인 (리눅스 top과 비슷)
  ```sh
  kubectl top pods
  ```
- `HPA`가 자원을 요청할 떄 메트릭 서버를 통해 계측값을 전달받으므로 메트릭 서버를 설정해야한다.

- 메트릭서버 또한 서비스와 마찬가지로 오브젝트 스펙파일로 설치 가능하다.
- scale 기준 값을 설정하여 파드 증설 시점을 지정 할 수 있다.
  #### edit 명령어로 디플로이먼트 설정 내용 수정
  ```yaml
  resources:
    requests:
      cpu: "10m" # cpu 0.01 사용을 기준으로 파드를 증설
    limits:
      cpu: "50m" # cpu 0.05로 사용 제한
  ```

  #### hpa-hname-pods에 autoscale을 설정
  ```sh
  kubectl autoscale deployment hpa-hname-pods --min=1 --max=30 --cpu-percent=50
  # min은 최소 파드의 수, max는 최대 파드의 수, cpu-percent는 CPU 사용량이 50% 넘을 떄 autoscale 하겠다는 조건
  ```